from transformers import AutoTokenizer
import torch

class LMTokenizer(AutoTokenizer):
    @classmethod
    def create(cls, model_variant: str = "gpt2-xl", **huggingface_kwargs):
        return cls.from_pretrained(model_variant, **huggingface_kwargs)
    
    def encode_text(self, text: str, truncate: bool = False) -> torch.Tensor:
        return self.encode(text, truncate=truncate)
    
    def decode_tokens(self, tokens: torch.Tensor) -> str:
        return self.decode(tokens)